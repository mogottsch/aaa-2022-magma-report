
@misc{giant_bicycles,
	title = {WIE SCHNELL FÄHRT EIN E-BIKE?},
	url = {https://www.giant-bicycles.com/de/campaigns/wie-schnell-fahrt-ein-e-bike/21531},
	urldate = {2022-06-05},
	author = {GiantBicycles},
	year = {2022},
	file = {},
}

@misc{german_weather_service,
	title = {Wetterdaten Deutscher Wetter Dienst},
	url = {https://opendata.dwd.de},
	urldate = {2022-05-27},
	author = {GermanWeatherService},
	year = {2022},
	file = {},
}

@misc{copernicus_land_use,
	title = {Wetterdaten Deutscher Wetter Dienst},
	url = {https://land.copernicus.eu/pan-european/corine-land-cover},
	urldate = {2022-05-27},
	author = {Copernicus},
	year = {2022},
	file = {},
}

@misc{peace_why_2019,
	title = {Why {You} {Don}’t {Want} a {Superfast} {Electric} {Bicycle} {\textbar} {Electric} {Bike} {Report} {\textbar} {Electric} {Bike}, {Ebikes}, {Electric} {Bicycles}, {E} {Bike}, {Reviews}},
	url = {https://electricbikereport.com/fast-electric-bike/},
	abstract = {Electric bicycles are wonderful devices for getting around; they are quick, convenient and great fun. But what happens when the motor (normally through modification or retro-fitting as a kit) assists the rider beyond the legal speed limit for motor assistance (generally 20mph in the USA and 15.5 mph in Europe). Whilst it might sound tempting […]},
	language = {en-US},
	urldate = {2022-01-27},
	author = {Peace, Richard},
	month = feb,
	year = {2019},
	file = {Snapshot:C\:\\Users\\kuian\\Zotero\\storage\\ZYC6SXBH\\fast-electric-bike.html:text/html},
}

@misc{uber_h3_2022,
	title = {H3 {\textbar} {H3}},
	url = {https://h3geo.org/},
	abstract = {Hexagonal hierarchical geospatial indexing system},
	language = {en},
	urldate = {2022-01-27},
	author = {Uber},
	year = {2022},
	file = {Snapshot:C\:\\Users\\kuian\\Zotero\\storage\\ZFBPGLH7\\h3geo.org.html:text/html},
}

@misc{iea_co2_2021,
	title = {{CO2} emissions – {Global} {Energy} {Review} 2021 – {Analysis}},
	url = {https://www.iea.org/reports/global-energy-review-2021/co2-emissions},
	abstract = {Global Energy Review 2021 - Analysis and key findings. A report by the International Energy Agency.},
	language = {en-GB},
	urldate = {2022-01-28},
	journal = {IEA},
	author = {IEA},
	year = {2021},
	file = {Snapshot:C\:\\Users\\kuian\\Zotero\\storage\\2FHE5MSB\\co2-emissions.html:text/html},
}

@misc{metrobikeshare_metro_2022,
	title = {Metro {Bike} {Share}},
	url = {https://bikeshare.metro.net/},
	abstract = {Metro Bike Share is the bike share system for Los Angeles. With hundreds of self service bikes available anytime, you can get a bike at any station, and return it to any station. Easy, fast, and fun, Metro Bike Share is human powered public transportation, on your schedule.},
	language = {en-US},
	urldate = {2022-01-28},
	journal = {Metro Bike Share},
	author = {MetroBikeShare},
	year = {2022},
	file = {Snapshot:C\:\\Users\\kuian\\Zotero\\storage\\5E5JHMBL\\bikeshare.metro.net.html:text/html},
}

@misc{nasa_causes_2022,
	title = {The {Causes} of {Climate} {Change}},
	url = {https://climate.nasa.gov/causes},
	abstract = {Most climate scientists agree the main cause of the current global warming trend is human expansion of the "greenhouse effect" — warming that results when the atmosphere traps heat radiating from Earth toward space.},
	urldate = {2022-01-28},
	journal = {Climate Change: Vital Signs of the Planet},
	author = {NASA},
	year = {2022},
	file = {Snapshot:C\:\\Users\\kuian\\Zotero\\storage\\P95846TL\\causes.html:text/html},
}

@article{DBLP:journals/corr/abs-2111-00970,
  author    = {Szymon Wozniak and
               Piotr Szymanski},
  title     = {Hex2vec - Context-Aware Embedding {H3} Hexagons with OpenStreetMap
               Tags},
  journal   = {CoRR},
  volume    = {abs/2111.00970},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.00970},
  eprinttype = {arXiv},
  eprint    = {2111.00970},
  timestamp = {Fri, 05 Nov 2021 15:25:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-00970.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}  
  
@article{schroer2022data,
  title={Data-Driven Competitor-Aware Positioning in On-Demand Vehicle Rental Networks},
  author={Schroer, Karsten and Ketter, Wolfgang and Lee, Thomas Y and Gupta, Alok and Kahlen, Micha},
  journal={Transportation Science},
  volume={56},
  number={1},
  pages={182--200},
  year={2022},
  publisher={INFORMS}
}
}

@INPROCEEDINGS{Williams01usingthe,
    author = {Christopher Williams and Matthias Seeger},
    title = {Using the Nyström Method to Speed Up Kernel Machines},
    booktitle = {Advances in Neural Information Processing Systems 13},
    year = {2001},
    pages = {682--688},
    publisher = {MIT Press}
}
@inproceedings{10.5555/2981562.2981710,
author = {Rahimi, Ali and Recht, Benjamin},
title = {Random Features for Large-Scale Kernel Machines},
year = {2007},
isbn = {9781605603520},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines.},
booktitle = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
pages = {1177–1184},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'07}
}
@article{bergstra,
author = {Bergstra, James and Bengio, Yoshua},
title = {Random Search for Hyper-Parameter Optimization},
year = {2012},
issue_date = {3/1/2012},
publisher = {JMLR.org},
volume = {13},
number = {null},
issn = {1532-4435},
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
journal = {J. Mach. Learn. Res.},
month = {feb},
pages = {281–305},
numpages = {25},
keywords = {model selection, deep learning, neural networks, global optimization, response surface modeling}
}


